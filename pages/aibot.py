# å¥³æœ‹å‹
# 1ã€aiå¾—çŸ¥é“ä»–æ˜¯ä½ çš„å¥³æœ‹å‹ langchainä¸­æç¤ºè¯æ¨¡å—æ¥é™å®š
#    å¥³æœ‹å‹çš„æ€§æ ¼å’Œç±»å‹ç”±ç”¨æˆ·é€‰æ‹©
# 2ã€aiè¿˜èƒ½èƒ½è®°ä½ç”¨æˆ·å’Œå®ƒèŠå¤©çš„è®°å½•
#    langchainçš„memoryè®°å¿†æ¨¡å—æ¥å®ç°
# 3ã€éœ€è¦ä½¿ç”¨langchainçš„chainé“¾ï¼Œé“¾æŠŠæç¤ºè¯+æ¨¡å‹+è®°å¿†è¿æ¥èµ·æ¥
# æ„å»ºæˆ‘ä»¬çš„æç¤ºè¯ï¼Œé€šè¿‡æç¤ºè¯æ¥ç»™å¤§æ¨¡å‹å®šä¹‰è§„åˆ™
import langchain
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory # åœ¨å†…å­˜ä¸­ä¿å­˜å†å²è®°å¿†çš„æ¨¡å—
from langchain.chains import ConversationChain
import backgroud.backgroud as bg


st.title('æ•°å­—æƒ…ç¼˜å®ˆæŠ¤è€…â¤ï¸â¤ï¸ğŸ’•â¤ï¸ğŸ’•')
st.subheader("éšæ—¶åœ¨çº¿ï¼Œåªä¸ºä½ å¿ƒåŠ¨")
if "gms" not in st.session_state:
    st.session_state.gms =[]

for gm in st.session_state.gms:
    with st.chat_message(gm["role"]):
        st.write(gm["context"])


# æ„å»ºçš„å¤§æ¨¡å‹
llm = ChatOpenAI(
    model="glm-4-0520",
    api_key="457e3a55c2035be3869a49e1ce5cba74.oARHiQyMbiR0UJCz",
    temperature=0.99,
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
# æ„å»ºè®°å¿†æ¨¡å—
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory()
# é€šè¿‡é“¾æŠŠä¸‰ä¸ªæ¨¡å—ç»™è¿æ¥èµ·æ¥
# ConversationChainé“¾ä¹‹æ‰€ä»¥èƒ½æ‰€ä»¥å†å²è®°å¿†å­˜å‚¨ï¼Œä¸»è¦æ˜¯å› ä¸ºä¼šåšä¸€ä»¶äº‹æƒ…ï¼Œä¼šæŠŠmemoryè®°å¿†æ¨¡å—ä¸­çš„æ•°æ®ä»¥historyå‚æ•°åçš„å½¢å¼
# å°è£…åˆ°é“¾çš„PromptTemplateæç¤ºè¯æ¨¡æ¿å½“ä¸­
temp = "ç°åœ¨ä½ è¦æ‰®æ¼”ä¸€ä¸ªç”·æœ‹å‹çš„è§’è‰²ï¼Œä½ çš„æ€§æ ¼æ˜¯"+st.session_state.xingge+"ï¼Œä½ åªéœ€è¦å›ç­”ä½ å¥³æœ‹å‹çš„è¯å³å¯ï¼Œä¸éœ€è¦é‡å¤ç”¨æˆ·çš„è¯ï¼Œä¹Ÿä¸éœ€è¦å°†ä½ çš„è§’è‰²å’Œæ€§æ ¼è¿›è¡Œå±•ç¤ºã€‚ä½ çš„å¥³æœ‹å‹è¯´çš„è¯æ˜¯:{input},ä½ ä»¬çš„ä»¥å‰çš„å¯¹è¯æ˜¯{history}"
prompt = PromptTemplate(
    input_variables=["input","history"],
    template=temp
)
chain = ConversationChain(
    prompt=prompt,
    llm=llm,
    memory=st.session_state.memory
)

input = st.chat_input("å’Œä½ çš„å¥³å‹è¯´ç‚¹è¯å§")
if input:
    with st.chat_message("user"):
        st.write(input)
    st.session_state.gms.append({"role":"user","context":input})
    # è°ƒç”¨å¤§æ¨¡å‹å›ç­”æˆ‘ä»¬çš„é—®é¢˜
    result = chain.invoke(input)
    # å¸¦æœ‰è®°å¿†çš„é“¾resultä¸­æ²¡æœ‰content,
    with st.chat_message("assistant"):
        st.write(result["response"])
    st.session_state.gms.append({"role":"assistant","context":result["response"]})
bg.main_bg('image/ai1.jpg')

